{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install osmnx torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:01:34.558118Z","iopub.execute_input":"2025-12-19T16:01:34.558809Z","iopub.status.idle":"2025-12-19T16:01:38.883373Z","shell.execute_reply.started":"2025-12-19T16:01:34.558776Z","shell.execute_reply":"2025-12-19T16:01:38.882422Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: osmnx in /usr/local/lib/python3.12/dist-packages (2.0.7)\nRequirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\nRequirement already satisfied: geopandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from osmnx) (1.1.1)\nRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from osmnx) (3.5)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.0.2)\nRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.2.2)\nRequirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.32.5)\nRequirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.1.2)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\nRequirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (0.11.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (25.0)\nRequirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (3.7.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2025.11.12)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport shutil\nimport numpy as np\nimport os.path as osp\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import NearestNeighbors # Dùng cái này để tìm k-NN\n\n# Import PyG dependencies\nimport torch_geometric\nfrom torch_geometric.data import Data, InMemoryDataset, download_url\nfrom torch_geometric.nn import GATv2Conv, GCNConv\n\n# Thiết lập thiết bị\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# ==============================================================================\n# 1. TRAVELDataset (Giữ nguyên)\n# ==============================================================================\n\ndef read_npz(path):\n    with np.load(path, allow_pickle=True) as f:\n        return parse_npz(f)\n\ndef parse_npz(f):\n    x = torch.from_numpy(f['x']).to(torch.float)\n    coords = torch.from_numpy(f['coordinates']).to(torch.float)\n    edge_attr = torch.from_numpy(f['edge_attr']).to(torch.float)\n    occur_labels = torch.from_numpy(f['occur_labels']).to(torch.long)\n    edge_index = torch.from_numpy(f['edge_index']).to(torch.long).t().contiguous()\n    try:\n        severity_labels = torch.from_numpy(f['severity_8labels']).to(torch.long)\n    except:\n        severity_labels = torch.zeros_like(occur_labels)\n\n    return Data(x=x, y=occur_labels, severity_labels=severity_labels, \n                edge_index=edge_index, edge_attr=edge_attr, coords=coords)\n\nclass TRAVELDataset(InMemoryDataset):\n    url = 'https://github.com/baixianghuang/travel/raw/main/TAP-city/{}.npz'\n\n    def __init__(self, root, name, transform=None, pre_transform=None):\n        self.name = name.lower()\n        super().__init__(root, transform, pre_transform)\n        try:\n            self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n        except TypeError:\n            self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_dir(self): return osp.join(self.root, self.name, 'raw')\n    @property\n    def processed_dir(self): return osp.join(self.root, self.name, 'processed')\n    @property\n    def raw_file_names(self): return f'{self.name}.npz'\n    @property\n    def processed_file_names(self): return 'data.pt'\n\n    def download(self):\n        download_url(self.url.format(self.name), self.raw_dir)\n\n    def process(self):\n        data = read_npz(self.raw_paths[0])\n        if self.pre_transform is not None:\n            data = self.pre_transform(data)\n        torch.save(self.collate([data]), self.processed_paths[0])\n\n# ==============================================================================\n# 2. Xây dựng đồ thị k-NN (Giải pháp triệt để cho vấn đề RAM)\n# ==============================================================================\n\ndef construct_knn_graphs(data, k=15, sigma=1.0):\n    \"\"\"\n    Sử dụng k-Nearest Neighbors để giới hạn số lượng cạnh.\n    Đảm bảo bộ nhớ không bao giờ bị tràn.\n    k: Số lượng hàng xóm tối đa cho mỗi nút (vd: 10, 15, 20).\n    \"\"\"\n    print(f\"Constructing k-NN graphs (k={k}) on CPU...\")\n    \n    coords = data.coords.cpu().numpy()\n    num_nodes = len(coords)\n    \n    # Sử dụng Sklearn NearestNeighbors (Rất nhanh và nhẹ RAM)\n    # algorithm='kd_tree' giúp tìm kiếm nhanh\n    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='kd_tree').fit(coords)\n    distances, indices = nbrs.kneighbors(coords)\n    \n    # indices: [N, k+1] chứa index của các nút hàng xóm\n    # Cột 0 là chính nó (khoảng cách 0), ta bỏ qua hoặc giữ tùy ý. Ở đây ta bỏ cột 0.\n    knn_idx = indices[:, 1:] # [N, k]\n    knn_dist = distances[:, 1:] # [N, k]\n    \n    # Flatten để tạo edge_index\n    source_nodes = np.repeat(np.arange(num_nodes), k)\n    target_nodes = knn_idx.flatten()\n    dist_flat = knn_dist.flatten()\n    \n    # --- Tạo A1 (Physical Graph) ---\n    # Tính trọng số cạnh dựa trên khoảng cách\n    # weight = exp(-d^2 / sigma^2)\n    weights_a1 = np.exp(-(dist_flat**2) / (sigma**2))\n    \n    # Tạo edge_index tensor\n    edge_index_1 = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n    \n    # --- Tạo A2 (Accident Graph) ---\n    # Trọng số bị ảnh hưởng bởi intensity t của nút đích (target_nodes)\n    y_np = data.y.cpu().numpy()\n    t_vals = np.where(y_np > 0, 1.2, 1.0) # [N]\n    \n    # Lấy t tương ứng với mỗi cạnh (dựa vào target node)\n    t_targets = t_vals[target_nodes]\n    \n    weights_a2 = np.exp(-(dist_flat**2) / ((sigma**2) * t_targets))\n    \n    # Với k-NN, cấu trúc kết nối (topology) của A1 và A2 là giống nhau (đều là k hàng xóm),\n    # chỉ khác nhau ở trọng số (weights) dùng trong Attention.\n    # Trong mô hình GAT, ta chỉ cần truyền cấu trúc edge_index. \n    # (Để đơn giản và tiết kiệm, ta dùng chung edge_index, GAT sẽ tự học trọng số mới).\n    \n    # Chuyển sang device\n    edge_index = edge_index_1.to(device)\n    \n    print(f\" -> Total Edges: {edge_index.size(1)} (Fixed size: {num_nodes} * {k})\")\n    return edge_index\n\n# ==============================================================================\n# 3. Mô hình Sparse AI-GFACN\n# ==============================================================================\n\nclass SparseAIGFACN(nn.Module):\n    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):\n        super(SparseAIGFACN, self).__init__()\n        \n        # Embedding\n        self.embedding = nn.Sequential(\n            nn.Linear(num_features, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n        \n        # Dual Graph Processing\n        # Ta dùng 2 lớp GAT riêng biệt để học 2 góc nhìn khác nhau trên cùng tập hàng xóm\n        self.gat1 = GATv2Conv(hidden_dim, hidden_dim, heads=1, concat=True, dropout=dropout)\n        self.gat2 = GATv2Conv(hidden_dim, hidden_dim, heads=1, concat=True, dropout=dropout)\n        \n        # Fusion\n        self.gate_w = nn.Linear(2*hidden_dim, 1)\n        \n        # Decoder\n        self.gcn = GCNConv(hidden_dim, hidden_dim)\n        self.fc_out = nn.Linear(hidden_dim, num_classes)\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        h = self.embedding(x)\n        h = F.dropout(h, p=self.dropout, training=self.training)\n        \n        # Nhánh 1: Physical View (GAT sẽ tự học trọng số attention dựa trên features)\n        h1 = self.gat1(h, edge_index) \n        h1 = F.elu(h1)\n        \n        # Nhánh 2: Accident View\n        # Lưu ý: Trong bản gốc, A1 và A2 khác nhau về trọng số khởi tạo. \n        # Ở đây GATv2 đủ mạnh để tự tìm trọng số tối ưu khác nhau cho 2 nhánh.\n        h2 = self.gat2(h, edge_index) \n        h2 = F.elu(h2)\n        \n        # Gated Fusion\n        combined = torch.cat([h1, h2], dim=1)\n        z = torch.sigmoid(self.gate_w(combined))\n        h_fused = z * h1 + (1 - z) * h2\n        \n        # Final Processing\n        h_final = self.gcn(h_fused, edge_index)\n        h_final = F.relu(h_final)\n        h_final = F.dropout(h_final, p=self.dropout, training=self.training)\n        \n        out = self.fc_out(h_final)\n        return F.log_softmax(out, dim=1)\n\n# ==============================================================================\n# 4. Training Loop\n# ==============================================================================\n\ndef train_test_split_stratify(dataset, train_ratio, val_ratio, class_num):\n    labels = dataset[0].y\n    train_mask = torch.zeros(size=labels.shape, dtype=torch.bool)\n    val_mask = torch.zeros(size=labels.shape, dtype=torch.bool)\n    test_mask = torch.zeros(size=labels.shape, dtype=torch.bool)\n    \n    for i in range(class_num):\n        idx = np.argwhere(labels.cpu().numpy() == i).flatten()\n        np.random.shuffle(idx)\n        split1 = int(len(idx) * train_ratio)\n        split2 = split1 + int(len(idx) * val_ratio)\n        train_mask[idx[:split1]] = True\n        val_mask[idx[split1:split2]] = True\n        test_mask[idx[split2:]] = True\n    return train_mask, val_mask, test_mask\n\ndef run_experiment(city_name='los_angeles_ca', epochs=50):\n    root_path = './data_travel'\n    \n    print(f\"Loading data for {city_name}...\")\n    dataset = TRAVELDataset(root_path, city_name)\n    data = dataset[0]\n    \n    # Giải phóng bộ nhớ không cần thiết\n    data.edge_attr = None \n    \n    class_num = dataset.num_classes\n    train_mask, val_mask, test_mask = train_test_split_stratify(dataset, 0.6, 0.2, class_num)\n    \n    # Chuẩn hóa\n    sc = MinMaxScaler()\n    data.x = torch.tensor(sc.fit_transform(data.x.numpy()), dtype=torch.float)\n    \n    # Xây dựng đồ thị k-NN (Thay đổi k nếu cần, k càng nhỏ càng nhẹ)\n    # k=10 là con số rất an toàn cho mọi RAM\n    edge_index = construct_knn_graphs(data, k=10, sigma=1.0)\n    \n    # Move Data to GPU\n    data = data.to(device)\n    \n    # Model\n    model = SparseAIGFACN(num_features=dataset.num_features, hidden_dim=64, num_classes=class_num).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n    \n    print(\"-\" * 85)\n    print(f\"{'Epoch':<5} | {'Loss':<8} | {'Acc':<8} | {'MAE':<8} | {'RMSE':<8} | {'PCC':<8} | {'Time':<8}\")\n    print(\"-\" * 85)\n    \n    for epoch in range(1, epochs + 1):\n        t_start = time.time()\n        \n        model.train()\n        optimizer.zero_grad()\n        \n        output = model(data.x, edge_index)\n        loss = F.nll_loss(output[train_mask], data.y[train_mask])\n        \n        loss.backward()\n        optimizer.step()\n        \n        # Eval\n        model.eval()\n        with torch.no_grad():\n            output = model(data.x, edge_index)\n            probs = torch.exp(output)[:, 1]\n            preds = output.max(1)[1]\n            \n            y_true = data.y[test_mask].cpu().numpy()\n            y_pred = preds[test_mask].cpu().numpy()\n            y_prob = probs[test_mask].cpu().numpy()\n            \n            acc = accuracy_score(y_true, y_pred)\n            mae = mean_absolute_error(y_true, y_prob)\n            rmse = np.sqrt(mean_squared_error(y_true, y_prob))\n            \n            if np.std(y_prob) < 1e-9: pcc = 0.0\n            else:\n                pcc_val, _ = pearsonr(y_true, y_prob)\n                pcc = 0.0 if np.isnan(pcc_val) else pcc_val\n        \n        if epoch % 5 == 0 or epoch == 1:\n            print(f\"{epoch:<5} | {loss.item():<8.4f} | {acc:<8.4f} | {mae:<8.4f} | {rmse:<8.4f} | {pcc:<8.4f} | {time.time()-t_start:<8.4f}s\")\n\nif __name__ == \"__main__\":\n    if not osp.exists('./data_travel'):\n        os.makedirs('./data_travel')\n    \n    # Dọn dẹp cache\n    torch.cuda.empty_cache()\n    \n    try:\n        run_experiment('los_angeles_ca', epochs=200)\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:03:31.780524Z","iopub.execute_input":"2025-12-19T16:03:31.781217Z","iopub.status.idle":"2025-12-19T16:03:53.223649Z","shell.execute_reply.started":"2025-12-19T16:03:31.781182Z","shell.execute_reply":"2025-12-19T16:03:53.222660Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading data for los_angeles_ca...\nConstructing k-NN graphs (k=10) on CPU...\n -> Total Edges: 492510 (Fixed size: 49251 * 10)\n-------------------------------------------------------------------------------------\nEpoch | Loss     | Acc      | MAE      | RMSE     | PCC      | Time    \n-------------------------------------------------------------------------------------\n1     | 0.7834   | 0.8627   | 0.4921   | 0.4922   | 0.0169   | 0.1358  s\n5     | 0.4111   | 0.8698   | 0.1902   | 0.3403   | 0.0121   | 0.1037  s\n10    | 0.4160   | 0.8698   | 0.2260   | 0.3351   | 0.1003   | 0.1046  s\n15    | 0.4136   | 0.8698   | 0.2622   | 0.3366   | 0.2083   | 0.1037  s\n20    | 0.3902   | 0.8698   | 0.1898   | 0.3328   | 0.3037   | 0.1038  s\n25    | 0.3557   | 0.8700   | 0.2395   | 0.3139   | 0.4223   | 0.1040  s\n30    | 0.3175   | 0.8847   | 0.1626   | 0.2996   | 0.4765   | 0.1045  s\n35    | 0.3129   | 0.8795   | 0.1876   | 0.3005   | 0.4661   | 0.1038  s\n40    | 0.3122   | 0.8796   | 0.1642   | 0.2968   | 0.4748   | 0.1038  s\n45    | 0.3084   | 0.8798   | 0.1778   | 0.2964   | 0.4756   | 0.1046  s\n50    | 0.3063   | 0.8821   | 0.1718   | 0.2961   | 0.4768   | 0.1036  s\n55    | 0.3049   | 0.8829   | 0.1753   | 0.2959   | 0.4804   | 0.1043  s\n60    | 0.3053   | 0.8839   | 0.1730   | 0.2957   | 0.4814   | 0.1041  s\n65    | 0.3036   | 0.8843   | 0.1699   | 0.2955   | 0.4813   | 0.1036  s\n70    | 0.3039   | 0.8841   | 0.1758   | 0.2957   | 0.4816   | 0.1044  s\n75    | 0.3040   | 0.8842   | 0.1713   | 0.2956   | 0.4813   | 0.1041  s\n80    | 0.3016   | 0.8840   | 0.1694   | 0.2953   | 0.4820   | 0.1046  s\n85    | 0.3035   | 0.8842   | 0.1717   | 0.2959   | 0.4820   | 0.1036  s\n90    | 0.3016   | 0.8847   | 0.1727   | 0.2958   | 0.4825   | 0.1047  s\n95    | 0.3003   | 0.8842   | 0.1702   | 0.2953   | 0.4830   | 0.1047  s\n100   | 0.3017   | 0.8845   | 0.1700   | 0.2953   | 0.4834   | 0.1038  s\n105   | 0.3009   | 0.8847   | 0.1696   | 0.2953   | 0.4836   | 0.1054  s\n110   | 0.3016   | 0.8846   | 0.1706   | 0.2954   | 0.4839   | 0.1048  s\n115   | 0.3011   | 0.8846   | 0.1714   | 0.2953   | 0.4842   | 0.1041  s\n120   | 0.2995   | 0.8846   | 0.1705   | 0.2954   | 0.4843   | 0.1047  s\n125   | 0.3001   | 0.8847   | 0.1705   | 0.2952   | 0.4845   | 0.1045  s\n130   | 0.2997   | 0.8847   | 0.1699   | 0.2954   | 0.4844   | 0.1045  s\n135   | 0.3000   | 0.8845   | 0.1703   | 0.2952   | 0.4848   | 0.1048  s\n140   | 0.2989   | 0.8851   | 0.1689   | 0.2950   | 0.4853   | 0.1059  s\n145   | 0.2985   | 0.8848   | 0.1679   | 0.2951   | 0.4854   | 0.1047  s\n150   | 0.3005   | 0.8856   | 0.1698   | 0.2947   | 0.4859   | 0.1062  s\n155   | 0.2982   | 0.8860   | 0.1692   | 0.2947   | 0.4862   | 0.1050  s\n160   | 0.2992   | 0.8850   | 0.1697   | 0.2950   | 0.4859   | 0.1047  s\n165   | 0.2999   | 0.8850   | 0.1684   | 0.2950   | 0.4857   | 0.1051  s\n170   | 0.2983   | 0.8850   | 0.1652   | 0.2952   | 0.4849   | 0.1046  s\n175   | 0.2987   | 0.8849   | 0.1679   | 0.2953   | 0.4857   | 0.1049  s\n180   | 0.2968   | 0.8854   | 0.1690   | 0.2950   | 0.4866   | 0.1042  s\n185   | 0.2986   | 0.8854   | 0.1692   | 0.2949   | 0.4867   | 0.1050  s\n190   | 0.2974   | 0.8863   | 0.1720   | 0.2945   | 0.4870   | 0.1059  s\n195   | 0.2980   | 0.8864   | 0.1711   | 0.2945   | 0.4871   | 0.1050  s\n200   | 0.2991   | 0.8856   | 0.1702   | 0.2948   | 0.4864   | 0.1064  s\n","output_type":"stream"}],"execution_count":3}]}