{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================\n# 1. CÀI ĐẶT & IMPORT\n# ==========================================\n!pip install -q osmnx torch_geometric\n\nimport os\nimport shutil\nimport gc\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.data import InMemoryDataset, download_url, Data\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, f1_score, roc_auc_score, average_precision_score, mean_absolute_error, mean_squared_error\nfrom scipy.stats import pearsonr\nfrom tensorflow.keras import Model, layers, Input\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Reshape, BatchNormalization, Concatenate, Layer, Multiply\n\n# Thiết lập Random Seed\nseed = 7\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntorch.manual_seed(seed)\n\nprint(f\"TensorFlow Version: {tf.__version__}\")\n\n# ==========================================\n# 2. DATASET LOADER\n# ==========================================\ndef parse_npz(f):\n    crash_time = f['crash_time']\n    x = torch.from_numpy(f['x']).to(torch.float)\n    coords = torch.from_numpy(f['coordinates']).to(torch.float)\n    edge_attr = torch.from_numpy(f['edge_attr']).to(torch.float)\n    cnt_labels = torch.from_numpy(f['cnt_labels']).to(torch.long)\n    occur_labels = torch.from_numpy(f['occur_labels']).to(torch.long)\n    edge_attr_dir = torch.from_numpy(f['edge_attr_dir']).to(torch.float)\n    edge_attr_ang = torch.from_numpy(f['edge_attr_ang']).to(torch.float)\n    severity_labels = torch.from_numpy(f['severity_8labels']).to(torch.long)\n    edge_index = torch.from_numpy(f['edge_index']).to(torch.long).t().contiguous()\n    return Data(x=x, y=occur_labels, severity_labels=severity_labels, edge_index=edge_index,\n                edge_attr=edge_attr, edge_attr_dir=edge_attr_dir, edge_attr_ang=edge_attr_ang,\n                coords=coords, cnt_labels=cnt_labels, crash_time=crash_time)\n\ndef read_npz(path):\n    with np.load(path, allow_pickle=True) as f:\n        return parse_npz(f)\n\nclass TRAVELDataset(InMemoryDataset):\n    url = 'https://github.com/baixianghuang/travel/raw/main/TAP-city/{}.npz'\n    def __init__(self, root, name, transform=None, pre_transform=None):\n        self.name = name.lower()\n        super().__init__(root, transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n    @property\n    def raw_dir(self): return os.path.join(self.root, self.name, 'raw')\n    @property\n    def processed_dir(self): return os.path.join(self.root, self.name, 'processed')\n    @property\n    def raw_file_names(self): return f'{self.name}.npz'\n    @property\n    def processed_file_names(self): return 'data.pt'\n    def download(self): download_url(self.url.format(self.name), self.raw_dir)\n    def process(self):\n        data = read_npz(self.raw_paths[0])\n        data, slices = self.collate([data])\n        torch.save((data, slices), self.processed_paths[0])\n\n# ==========================================\n# 3. MODEL MG-TAR OPTIMIZED\n# ==========================================\nclass SparseGraphConvolution(Layer):\n    def __init__(self, units, activation=None, use_bias=True, **kwargs):\n        super(SparseGraphConvolution, self).__init__(**kwargs)\n        self.units = units\n        self.activation = tf.keras.activations.get(activation)\n        self.use_bias = use_bias\n    def build(self, input_shape):\n        feature_shape = input_shape[0]\n        input_dim = feature_shape[-1]\n        self.kernel = self.add_weight(shape=(input_dim, self.units), initializer='glorot_uniform', name='kernel')\n        if self.use_bias: self.bias = self.add_weight(shape=(self.units,), initializer='zeros', name='bias')\n        super(SparseGraphConvolution, self).build(input_shape)\n    def call(self, inputs):\n        features, adj_sparse = inputs\n        features_2d = tf.squeeze(features, axis=0)\n        shape = tf.shape(adj_sparse); N = shape[1]\n        adj_2d = tf.sparse.reshape(adj_sparse, [N, N])\n        support = tf.matmul(features_2d, self.kernel)\n        output = tf.sparse.sparse_dense_matmul(adj_2d, support)\n        output = tf.expand_dims(output, axis=0)\n        if self.use_bias: output = tf.nn.bias_add(output, self.bias)\n        if self.activation is not None: output = self.activation(output)\n        return output\n\nclass GatedFusionLayer(Layer):\n    def __init__(self, units, **kwargs):\n        super(GatedFusionLayer, self).__init__(**kwargs)\n        self.units = units\n        self.gate_proj = Dense(units, activation='sigmoid')\n    def call(self, inputs):\n        H_view, z_global = inputs\n        gate = self.gate_proj(z_global)\n        return Multiply()([H_view, gate])\n\ndef MG_TAR_Optimized(input_shape, n_districts, configs, length=1):\n    tf.keras.backend.clear_session()\n    gru_h, gcn_f, fc_h, n_layers, bn, d = configs\n    n_features = input_shape[-1]\n    inputs_adj = [Input(shape=(n_districts, n_districts), sparse=True, name=f'A_{i}') for i in range(5)]\n    F = Input(shape=[length, n_districts, n_features], name='Features')\n    Ft = Lambda(lambda f: f[:,0,:,:])(F)\n    states = [Ft for _ in range(5)]\n    final_embeds = []\n    pooled_embeds = []\n    gcn_layer_shared = SparseGraphConvolution(gcn_f, activation='relu')\n    for j in range(5):\n        x = gcn_layer_shared([states[j], inputs_adj[j]])\n        if bn: x = BatchNormalization()(x)\n        x = Dropout(0.1)(x)\n        final_embeds.append(x)\n        pooled_embeds.append(Lambda(lambda t: tf.reduce_mean(t, axis=1, keepdims=True))(x))\n    z_global = Concatenate(axis=-1)(pooled_embeds)\n    H_list = []\n    for j in range(5):\n        fusion_layer = GatedFusionLayer(units=gcn_f)\n        H_list.append(fusion_layer([final_embeds[j], z_global]))\n    H = Concatenate(axis=-1)(H_list)\n    H = Concatenate(axis=-1)([H, Ft])\n    H = Dense(fc_h, activation='relu')(H)\n    H = Dropout(0.3)(H)\n    H = Dense(32, activation='relu')(H)\n    y = Dense(1, activation='sigmoid')(H)\n    y = Reshape([n_districts])(y)\n    return Model(inputs=inputs_adj + [F], outputs=y)\n\n# ==========================================\n# 4. UTILS & LOSS\n# ==========================================\ndef masked_weighted_bce(mask, pos_weight):\n    def loss(y_true, y_pred):\n        mask_cast = tf.expand_dims(tf.cast(mask, dtype=tf.float32), 0)\n        weights = y_true * (pos_weight - 1.0) + 1.0\n        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n        return tf.reduce_sum(bce * weights * mask_cast) / (tf.reduce_sum(mask_cast) + 1e-9)\n    return loss\n\ndef get_sparse_adj_expanded(edge_index, num_nodes):\n    indices = edge_index.t().numpy()\n    values = np.ones(indices.shape[0], dtype=np.float32)\n    st = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=[num_nodes, num_nodes])\n    return tf.sparse.expand_dims(tf.sparse.reorder(st), 0)\n\ndef clean_data_leakage(X, y, threshold=0.85):\n    n_features = X.shape[1]\n    drop_indices = [i for i in range(n_features) if not np.isnan(X[:, i]).any() and abs(np.corrcoef(X[:, i], y)[0, 1]) > threshold]\n    if drop_indices:\n        print(f\"Removed leakage columns: {drop_indices}\")\n        return np.delete(X, drop_indices, axis=1)\n    return X\n\nclass ValidationCallback(tf.keras.callbacks.Callback):\n    def __init__(self, val_mask, inputs, y_true):\n        self.val_mask, self.inputs, self.y_true = val_mask, inputs, y_true\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % 5 == 0:\n            y_pred = self.model.predict(self.inputs, verbose=0)\n            y_true_val = self.y_true[0][self.val_mask == 1]\n            y_pred_val = (y_pred[0][self.val_mask == 1] > 0.5).astype(int)\n            print(f\" — val_f1: {f1_score(y_true_val, y_pred_val, zero_division=0):.4f}\")\n\n# ==========================================\n# 5. MAIN EXPERIMENT\n# ==========================================\ndef run_experiment_full_integration():\n    city_name = 'los_angeles_ca'\n    file_path = 'exp/'\n    if os.path.exists(file_path+city_name+'/processed'): shutil.rmtree(file_path+city_name+'/processed')\n\n    print(f\"Loading {city_name}...\")\n    dataset = TRAVELDataset(file_path, city_name)\n    data = dataset[0]\n\n    X_clean = clean_data_leakage(data.x.numpy(), data.y.numpy())\n    X_scaled = MinMaxScaler().fit_transform(X_clean)\n    \n    adj_sparse = get_sparse_adj_expanded(data.edge_index, data.num_nodes)\n    inputs_adj = [adj_sparse for _ in range(5)]\n    F_input = np.expand_dims(np.expand_dims(X_scaled, 0), 1)\n    y_true = np.expand_dims(data.y.numpy(), 0)\n\n    # Split\n    from sklearn.model_selection import train_test_split\n    train_idx, temp_idx = train_test_split(np.arange(data.num_nodes), test_size=0.4, stratify=data.y.numpy(), random_state=seed)\n    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=data.y.numpy()[temp_idx], random_state=seed)\n    \n    masks = [np.zeros(data.num_nodes) for _ in range(3)]\n    for i, idx in enumerate([train_idx, val_idx, test_idx]): masks[i][idx] = 1\n    train_mask, val_mask, test_mask = masks\n\n    # Weight Calculation\n    n_pos = np.sum(data.y.numpy()[train_idx] == 1)\n    pos_weight = np.sum(data.y.numpy()[train_idx] == 0) / (n_pos + 1e-5)\n    print(f\"Pos Weight: {pos_weight:.2f}\")\n\n    # Model & Train\n    model = MG_TAR_Optimized(X_scaled.shape, data.num_nodes, [64, 32, 64, 2, False, 1.0])\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=masked_weighted_bce(train_mask, pos_weight), jit_compile=False)\n    \n    inputs_full = inputs_adj + [F_input]\n    print(\"\\nStarting Training...\")\n    model.fit(inputs_full, y_true, epochs=100, batch_size=1, verbose=1, \n              callbacks=[ValidationCallback(val_mask, inputs_full, y_true), \n                         tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)])\n\n    # --- EVALUATION ---\n    print(\"\\n=== FINAL EVALUATION ===\")\n    y_pred_prob = model.predict(inputs_full)[0]\n    y_test = data.y.numpy()[test_mask == 1]\n    y_prob = y_pred_prob[test_mask == 1]\n\n    # Find Best Threshold\n    best_f1, best_thresh = 0, 0.5\n    for thresh in np.arange(0.1, 0.9, 0.05):\n        f1 = f1_score(y_test, (y_prob > thresh).astype(int), zero_division=0)\n        if f1 > best_f1: best_f1, best_thresh = f1, thresh\n    \n    y_pred = (y_prob > best_thresh).astype(int)\n    print(f\"Best Threshold: {best_thresh:.2f}\")\n    print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n    print(f\"AUC: {roc_auc_score(y_test, y_prob):.4f} | MAP: {average_precision_score(y_test, y_prob):.4f}\")\n\n    # --- MAE, RMSE, PCC ---\n    print(\"\\n=== ADDITIONAL METRICS (MAE, RMSE, PCC) ===\")\n    \n    # 1. Binary Metrics (Dựa trên nhãn 0/1 sau khi threshold)\n    mae_bin = mean_absolute_error(y_test, y_pred)\n    rmse_bin = np.sqrt(mean_squared_error(y_test, y_pred))\n    pcc_bin, _ = pearsonr(y_test, y_pred)\n    print(f\"[Binary Prediction] MAE: {mae_bin:.4f} | RMSE: {rmse_bin:.4f} | PCC: {pcc_bin:.4f}\")\n\n    # 2. Probability Metrics (Dựa trên xác suất gốc)\n    mae_prob = mean_absolute_error(y_test, y_prob)\n    rmse_prob = np.sqrt(mean_squared_error(y_test, y_prob))\n    pcc_prob, _ = pearsonr(y_test, y_prob)\n    print(f\"[Risk Probability]  MAE: {mae_prob:.4f} | RMSE: {rmse_prob:.4f} | PCC: {pcc_prob:.4f}\")\n\n    del model, inputs_full; gc.collect()\n\nif __name__ == \"__main__\":\n    run_experiment_full_integration()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:23:44.895463Z","iopub.execute_input":"2025-12-30T02:23:44.895829Z","iopub.status.idle":"2025-12-30T02:24:34.059123Z","shell.execute_reply.started":"2025-12-30T02:23:44.895787Z","shell.execute_reply":"2025-12-30T02:24:34.058154Z"}},"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.19.0\nLoading los_angeles_ca...\n","output_type":"stream"},{"name":"stderr","text":"Processing...\nDone!\n","output_type":"stream"},{"name":"stdout","text":"Pos Weight: 6.69\n\nStarting Training...\nEpoch 1/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 1.5306 — val_f1: 0.2259\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 1.5306\nEpoch 2/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.4301\nEpoch 3/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 1.3448\nEpoch 4/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.2747\nEpoch 5/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.2130\nEpoch 6/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.1612 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911ms/step - loss: 1.1612\nEpoch 7/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.1176\nEpoch 8/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.0756\nEpoch 9/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.0389\nEpoch 10/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.0039\nEpoch 11/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.9701 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step - loss: 0.9701\nEpoch 12/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.9366\nEpoch 13/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.9066\nEpoch 14/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.8775\nEpoch 15/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.8472\nEpoch 16/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.8203 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906ms/step - loss: 0.8203\nEpoch 17/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.7968\nEpoch 18/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.7745\nEpoch 19/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.7532\nEpoch 20/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.7351\nEpoch 21/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7194 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933ms/step - loss: 0.7194\nEpoch 22/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.7082\nEpoch 23/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.6975\nEpoch 24/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.6898\nEpoch 25/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.6846\nEpoch 26/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.6821 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883ms/step - loss: 0.6821\nEpoch 27/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.6808\nEpoch 28/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.6834\nEpoch 29/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 0.6821\nEpoch 30/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.6866\nEpoch 31/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6823 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915ms/step - loss: 0.6823\nEpoch 32/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6858\nEpoch 33/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.6827\nEpoch 34/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.6805\nEpoch 35/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.6751\nEpoch 36/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6709 — val_f1: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897ms/step - loss: 0.6709\nEpoch 37/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.6706\nEpoch 38/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.6664\nEpoch 39/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.6611\nEpoch 40/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6579\nEpoch 41/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.6548 — val_f1: 0.0016\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919ms/step - loss: 0.6548\nEpoch 42/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.6523\nEpoch 43/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.6483\nEpoch 44/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.6465\nEpoch 45/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.6446\nEpoch 46/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6424 — val_f1: 0.1175\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step - loss: 0.6424\nEpoch 47/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.6424\nEpoch 48/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6399\nEpoch 49/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6396\nEpoch 50/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.6385\nEpoch 51/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.6368 — val_f1: 0.1474\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914ms/step - loss: 0.6368\nEpoch 52/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6337\nEpoch 53/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.6328\nEpoch 54/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6320\nEpoch 55/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.6304\nEpoch 56/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.6270 — val_f1: 0.1487\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921ms/step - loss: 0.6270\nEpoch 57/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.6249\nEpoch 58/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.6252\nEpoch 59/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6241\nEpoch 60/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.6216\nEpoch 61/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.6186 — val_f1: 0.1523\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906ms/step - loss: 0.6186\nEpoch 62/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.6199\nEpoch 63/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.6170\nEpoch 64/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.6173\nEpoch 65/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6161\nEpoch 66/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.6124 — val_f1: 0.1679\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898ms/step - loss: 0.6124\nEpoch 67/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.6116\nEpoch 68/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.6101\nEpoch 69/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6084\nEpoch 70/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.6080\nEpoch 71/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.6057 — val_f1: 0.1667\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912ms/step - loss: 0.6057\nEpoch 72/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.6050\nEpoch 73/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 0.6016\nEpoch 74/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.6010\nEpoch 75/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.6022\nEpoch 76/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.5997 — val_f1: 0.1553\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892ms/step - loss: 0.5997\nEpoch 77/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.5969\nEpoch 78/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.5985\nEpoch 79/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.5950\nEpoch 80/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.5956\nEpoch 81/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5922 — val_f1: 0.1553\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913ms/step - loss: 0.5922\nEpoch 82/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.5931\nEpoch 83/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.5897\nEpoch 84/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.5889\nEpoch 85/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.5886\nEpoch 86/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.5887 — val_f1: 0.1566\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919ms/step - loss: 0.5887\nEpoch 87/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.5848\nEpoch 88/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.5864\nEpoch 89/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.5837\nEpoch 90/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.5828\nEpoch 91/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.5829 — val_f1: 0.1591\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945ms/step - loss: 0.5829\nEpoch 92/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.5820\nEpoch 93/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.5805\nEpoch 94/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.5790\nEpoch 95/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.5795\nEpoch 96/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.5774 — val_f1: 0.2035\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870ms/step - loss: 0.5774\nEpoch 97/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.5765\nEpoch 98/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.5761\nEpoch 99/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.5761\nEpoch 100/100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.5737\n\n=== FINAL EVALUATION ===\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\nBest Threshold: 0.20\n              precision    recall  f1-score   support\n\n           0     0.9121    0.9042    0.9081      8569\n           1     0.3945    0.4173    0.4056      1282\n\n    accuracy                         0.8408      9851\n   macro avg     0.6533    0.6608    0.6569      9851\nweighted avg     0.8447    0.8408    0.8427      9851\n\nAUC: 0.7615 | MAP: 0.4082\n\n=== ADDITIONAL METRICS (MAE, RMSE, PCC) ===\n[Binary Prediction] MAE: 0.1592 | RMSE: 0.3990 | PCC: 0.3140\n[Risk Probability]  MAE: 0.1937 | RMSE: 0.3095 | PCC: 0.3941\n","output_type":"stream"}],"execution_count":8}]}