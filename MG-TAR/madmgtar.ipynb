{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14203902,"sourceType":"datasetVersion","datasetId":9059075}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.modules.module import Module\nimport numpy as np\nimport pandas as pd\nimport scipy.sparse as sp\nfrom scipy.sparse import linalg\nfrom sklearn.preprocessing import MinMaxScaler\nimport math\nimport os\n\n# --- 1. Missing Utils Implementation ---\ndef calculate_normalized_laplacian(adj):\n    adj = sp.coo_matrix(adj)\n    d = np.array(adj.sum(1))\n    d_inv_sqrt = np.power(d, -0.5).flatten()\n    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n    normalized_laplacian = sp.eye(adj.shape[0]) - adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n    return normalized_laplacian\n\ndef scaled_Laplacian(W):\n    '''\n    Compute \\tilde{L}\n    '''\n    assert W.shape[0] == W.shape[1]\n    L = calculate_normalized_laplacian(W)\n    lambda_max, _ = linalg.eigsh(L, 1, which='LM')\n    lambda_max = lambda_max[0]\n    L = sp.csr_matrix(L)\n    M, _ = L.shape\n    I = sp.identity(M, format='csr', dtype=L.dtype)\n    L = (2 / lambda_max * L) - I\n    return L.astype(np.float32).todense()\n\ndef cheb_polynomial(L_tilde, K):\n    '''\n    Compute a list of chebyshev polynomials from T_0 to T_{K-1}\n    '''\n    N = L_tilde.shape[0]\n    cheb_polynomials = [torch.eye(N).to(L_tilde.device), L_tilde]\n    for i in range(2, K):\n        cheb_polynomials.append(2 * L_tilde @ cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n    return cheb_polynomials\n\ndef get_incidence_matrix(adj):\n    '''\n    Generate Incidence Matrix (M) and Edge Adjacency (adj_edge) from Node Adjacency\n    '''\n    rows, cols = np.where(adj > 0)\n    num_nodes = adj.shape[0]\n    num_edges = len(rows)\n    \n    # Incidence Matrix: Shape [Nodes, Edges]\n    M = np.zeros((num_nodes, num_edges), dtype=np.float32)\n    \n    # Edge Adjacency: Line Graph\n    adj_edge = np.zeros((num_edges, num_edges), dtype=np.float32)\n    \n    edge_map = {} # Key: (u, v), Value: edge_index\n    \n    for k, (u, v) in enumerate(zip(rows, cols)):\n        M[u, k] = 1\n        M[v, k] = 1 # Undirected or directed handling\n        edge_map[(u, v)] = k\n        \n    # Build Line Graph (Simple version: edges sharing a node are connected)\n    # This is heavy for large graphs, simplified for demo\n    for i in range(num_edges):\n        u1, v1 = rows[i], cols[i]\n        for j in range(i + 1, num_edges):\n            u2, v2 = rows[j], cols[j]\n            if u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2:\n                adj_edge[i, j] = 1\n                adj_edge[j, i] = 1\n                \n    return M, adj_edge\n\n# --- 2. Metrics (MAE, RMSE, PCC) ---\ndef compute_metrics(pred, target):\n    # Flatten\n    pred = pred.flatten()\n    target = target.flatten()\n    \n    # MAE\n    mae = torch.mean(torch.abs(pred - target)).item()\n    \n    # RMSE\n    rmse = torch.sqrt(torch.mean((pred - target) ** 2)).item()\n    \n    # PCC\n    vx = pred - torch.mean(pred)\n    vy = target - torch.mean(target)\n    pcc = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n    pcc = pcc.item()\n    \n    return mae, rmse, pcc\n\n# --- 3. Data Loader (Adapted from MG_TAR) ---\n# Assuming 'datasets' folder structure exists as per MG_TAR logic.\n# If not, this function expects the arrays to be loaded in memory.\n# Here we simulate the loading to bridge the gap.\n\nclass MGTARDataset(torch.utils.data.Dataset):\n    def __init__(self, X_node, Y):\n        self.X_node = torch.FloatTensor(X_node)\n        self.Y = torch.FloatTensor(Y)\n        \n    def __len__(self):\n        return len(self.X_node)\n    \n    def __getitem__(self, idx):\n        return self.X_node[idx], self.Y[idx]\n\ndef load_mgtar_data(data_path, city, year, length=12, n_steps=6):\n    # This calls the original data_loader function provided in your prompt\n    # Note: Ensure data_loader function is defined in the scope (I will wrap the import)\n    # Since I cannot import 'data_loader' from a file here, I assume the code block provided \n    # in the prompt regarding 'data_loader' is available or I simulate the output.\n    \n    # For demonstration, I will use the logic to return the shapes.\n    # In a real run, verify paths exist.\n    \n    # --- MOCK DATA LOADING for Model Verification if files missing ---\n    # Replace this block with actual: datasets = data_loader(data_path, city, ...)\n    print(\"Loading Data (Simulating MG_TAR structure)...\")\n    num_samples = 500\n    num_nodes = 25 # e.g. Seoul districts\n    n_features = 15 # risk + weather + etc.\n    \n    # Create random data mimicking the output of data_loader\n    X_train = np.random.rand(num_samples, length, num_nodes, n_features).astype(np.float32)\n    Y_train = np.random.rand(num_samples, n_steps, num_nodes, 1).astype(np.float32) # predicting risk\n    \n    X_test = np.random.rand(100, length, num_nodes, n_features).astype(np.float32)\n    Y_test = np.random.rand(100, n_steps, num_nodes, 1).astype(np.float32)\n    \n    # Adjacency matrix (simulating district connectivity)\n    adj = np.random.randint(0, 2, (num_nodes, num_nodes)).astype(np.float32)\n    np.fill_diagonal(adj, 1)\n    \n    return X_train, Y_train, X_test, Y_test, adj","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-20T05:08:25.844669Z","iopub.execute_input":"2025-12-20T05:08:25.844904Z","iopub.status.idle":"2025-12-20T05:08:30.321611Z","shell.execute_reply.started":"2025-12-20T05:08:25.844883Z","shell.execute_reply":"2025-12-20T05:08:30.320588Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# --- Reuse classes provided in prompt ---\n# (Including GraphConvolution, GCN, MGCN_Standard, BGCN, MRA_BGCN, Encoder_GRU_MRA, Decoder_GRU_MRA, Enc_Dec_MRA)\n\nclass GraphConvolution(Module):\n    def __init__(self, in_features, out_features, device, bias=True):\n        super(GraphConvolution, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.DEVICE = device\n        self.weight = Parameter(torch.FloatTensor(in_features, out_features).to(self.DEVICE))\n        if bias:\n            self.bias = Parameter(torch.FloatTensor(out_features).to(self.DEVICE))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        if self.bias is not None:\n            self.bias.data.uniform_(-stdv, stdv)\n\n    def forward(self, input, adj):\n        support = torch.mm(input, self.weight)\n        output = torch.spmm(adj, support)\n        if self.bias is not None:\n            return output + self.bias\n        else:\n            return output\n\nclass GCN(nn.Module):\n    def __init__(self, L_tilde, dim_in, dim_out, order_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(GCN, self).__init__()\n        self.DEVICE = device\n        self.order_K = order_K\n        self.L_tilde = L_tilde\n        self.dim_in = dim_in\n        self.dim_out = dim_out\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(dim_in, dim_out)) for _ in range(order_K)])\n        self.weights = nn.Parameter(torch.FloatTensor(size=(dim_out, dim_out)))\n        self.biases = nn.Parameter(torch.FloatTensor(size=(dim_out,)))\n        self._in_drop = in_drop\n        self._gcn_drop = gcn_drop\n        self._residual = residual\n        self.linear = nn.Linear(dim_in, dim_out)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        for theta in self.Theta:\n            nn.init.xavier_uniform_(theta)\n        nn.init.xavier_uniform_(self.weights)\n        nn.init.zeros_(self.biases)\n\n    def forward(self, x, state=None, M=None):\n        batch_size, num_of_vertices, in_channels = x.shape\n        output = torch.zeros(batch_size, num_of_vertices, self.dim_out).to(self.DEVICE)\n        cheb_polynomials = cheb_polynomial(self.L_tilde, self.order_K)\n        \n        if state is not None:\n             # Logic xử lý tương tác bipartite (M)\n            s = torch.einsum('ij,jkm->ikm', M, state.permute(1, 0, 2)).permute(1, 0, 2)\n            x = torch.cat((x, s), dim=-1)\n            \n        x0 = x\n        if self._in_drop != 0:\n            x = torch.dropout(x, 1.0 - self._in_drop, train=True)\n            \n        # Do input x thay đổi dimension nếu có state gộp vào\n        # Cần điều chỉnh linear layer nếu dimensions thay đổi dynamic (đơn giản hóa ở đây giả định dim khớp)\n        \n        for k in range(self.order_K):\n            # Chebyshev recurrence\n            # [Batch, N, Fin] * [N, N] -> [Batch, N, Fin] * [Fin, Fout]\n            # PyTorch matmul handles broadcasting\n            theta = self.Theta[k]\n            # Fix dimension mismatch hack for demo if state injection changes dim\n            if x.shape[-1] != theta.shape[0]: \n                # Re-init generic linear projection for simplicity in this wrapper\n                x_proj = nn.Linear(x.shape[-1], theta.shape[0]).to(self.DEVICE)(x)\n                support = x_proj.permute(0, 2, 1).matmul(cheb_polynomials[k]).permute(0, 2, 1).matmul(theta)\n            else:\n                support = x.permute(0, 2, 1).matmul(cheb_polynomials[k]).permute(0, 2, 1).matmul(theta)\n            output = output + support\n            \n        output = torch.matmul(output, self.weights)\n        output = output + self.biases\n        res = F.relu(output)\n        if self._gcn_drop != 0.0:\n            res = torch.dropout(res, 1.0 - self._gcn_drop, train=True)\n        if self._residual:\n            if x0.shape[-1] != self.dim_out:\n                x0 = nn.Linear(x0.shape[-1], self.dim_out).to(self.DEVICE)(x0)\n            res = res + x0\n        return res\n\nclass BGCN(nn.Module):\n    def __init__(self, adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(BGCN, self).__init__()\n        self.DEVICE = device\n        self.K = range_K\n        self._M = M\n        GCN_khops_node = []\n        for k in range(self.K):\n            if k == 0:\n                GCN_khops_node.append(GCN(adj_node, dim_in_node, dim_out_node, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual))\n            else:\n                # Dim in increased due to edge interaction\n                GCN_khops_node.append(GCN(adj_node, dim_out_node + dim_out_edge, dim_out_node, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual))\n        self.GCN_khops_node = nn.ModuleList(GCN_khops_node)\n        self.GCN_khops_edge = nn.ModuleList([GCN(adj_edge, dim_out_edge, dim_out_edge, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual) for k in range(self.K)])\n        self.W_b = nn.Parameter(torch.FloatTensor(dim_in_node, dim_out_edge))\n        nn.init.xavier_uniform_(self.W_b)\n\n    def forward(self, X):\n        Xs = []\n        # Initial Edge Features derived from Nodes via Incidence Matrix M\n        # X: [Batch, N, F] -> [Batch, N, F] * [N, E] (via M) -> needs careful mapping\n        # Z0 calculation: M^T * X * W_b\n        # M: [N, E] -> M.T: [E, N]\n        # X: [B, N, F]\n        # X permute: [B, F, N]\n        \n        # Simplified logic for M interaction\n        X_flat = X.permute(0, 2, 1) # [B, F, N]\n        Z0 = torch.matmul(X_flat, self._M) # [B, F, E]\n        Z0 = Z0.permute(0, 2, 1) # [B, E, F]\n        Z0 = torch.matmul(Z0, self.W_b) if Z0.shape[-1] == self.W_b.shape[0] else nn.Linear(Z0.shape[-1], self.W_b.shape[1]).to(self.DEVICE)(Z0)\n\n        for k in range(self.K):\n            Z0 = self.GCN_khops_edge[k](Z0)\n            if k == 0:\n                X = self.GCN_khops_node[k](X)\n            else:\n                X = self.GCN_khops_node[k](X, Z0, self._M)\n            Xs.append(X)\n        Xs = torch.stack(Xs)\n        return Xs\n\nclass MRA_BGCN(nn.Module):\n    def __init__(self, adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, dim_out, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(MRA_BGCN, self).__init__()\n        self.DEVICE = device\n        self.dim_out = dim_out\n        self.W_a = nn.Parameter(torch.FloatTensor(dim_out_node, dim_out_node)) # Fixed dim mapping\n        self.U = nn.Parameter(torch.FloatTensor(dim_out_node))\n        self.BGCN = BGCN(adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        nn.init.xavier_uniform_(self.W_a)\n        nn.init.uniform_(self.U)\n\n    def forward(self, X):\n        input = self.BGCN(X) # [K, B, N, F_out]\n        # Attention mechanism\n        # input: [K, B, N, F]\n        e = torch.einsum('kbnf,ff->kbn', input, self.W_a) # Simplified attention\n        e = torch.einsum('kbn,f->kbn', e, self.U) # This logic was slightly broken in prompt, simplified here\n        \n        # Corrected Attention logic based on shapes\n        # input: [K, Batch, Node, Feat]\n        temp = torch.matmul(input, self.W_a) \n        e = torch.matmul(temp, self.U) # [K, Batch, Node]\n        \n        alpha = F.softmax(e, dim=0).unsqueeze(-1) # Softmax over K\n        h = torch.sum(input * alpha, dim=0)\n        \n        # Project to dim_out if needed\n        if h.shape[-1] != self.dim_out:\n            h = nn.Linear(h.shape[-1], self.dim_out).to(self.DEVICE)(h)\n            \n        return h\n\nclass Encoder_GRU_MRA(nn.Module):\n    def __init__(self, dim_in_enc, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Encoder_GRU_MRA, self).__init__()\n        self.DEVICE = device\n        self.dim_in_enc = dim_in_enc\n        # Input to gate is cat(x, h), so dim is feature + hidden\n        self.gate = MRA_BGCN(adj_node, adj_edge, self.dim_in_enc * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_enc * 2, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.update = MRA_BGCN(adj_node, adj_edge, self.dim_in_enc * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_enc, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.W = nn.Parameter(torch.FloatTensor(self.dim_in_enc, self.dim_in_enc))\n        self.b = nn.Parameter(torch.FloatTensor(self.dim_in_enc, ))\n        nn.init.xavier_uniform_(self.W)\n        nn.init.zeros_(self.b)\n\n    def forward(self, inputs=None, hidden_state=None):\n        batch_size, seq_len, num_vertice, feature = inputs.shape\n        output_inner = []\n        if hidden_state is None:\n            hx = torch.zeros((batch_size, num_vertice, feature)).to(self.DEVICE)\n        else:\n            hx = hidden_state\n        for index in range(seq_len):\n            x = inputs[:, index]\n            combined = torch.cat((x, hx), 2)\n            gates = self.gate(combined)\n            resetgate, updategate = torch.split(gates, self.dim_in_enc, dim=2)\n            resetgate = torch.sigmoid(resetgate)\n            updategate = torch.sigmoid(updategate)\n            \n            combined_update = torch.cat((x, (resetgate * hx)), 2)\n            cy = torch.tanh(self.update(combined_update))\n            hy = updategate * hx + (1.0 - updategate) * cy\n            hx = hy\n            yt = torch.sigmoid(hy.matmul(self.W) + self.b)\n            output_inner.append(yt)\n        output_inner = torch.stack(output_inner, dim=1) # [B, Seq, N, F]\n        return output_inner, hx\n\nclass Decoder_GRU_MRA(nn.Module):\n    def __init__(self, seq_target, dim_in_dec, dim_out_dec, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Decoder_GRU_MRA, self).__init__()\n        self.DEVICE = device\n        self.seq_target = seq_target\n        self.dim_in_dec = dim_in_dec\n        self.dim_out_dec = dim_out_dec\n        self.gate = MRA_BGCN(adj_node, adj_edge, self.dim_in_dec * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_dec * 2, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.update = MRA_BGCN(adj_node, adj_edge, self.dim_in_dec * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_dec, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.W = nn.Parameter(torch.FloatTensor(self.dim_in_dec, self.dim_out_dec))\n        self.b = nn.Parameter(torch.FloatTensor(self.dim_out_dec, ))\n        nn.init.xavier_uniform_(self.W)\n        nn.init.zeros_(self.b)\n\n    def forward(self, inputs=None, hidden_state=None):\n        # Inputs here is usually the last state of encoder or previous pred\n        batch_size, num_vertice, feature = inputs.shape\n        output_inner = []\n        hx = hidden_state\n        x = inputs # Autoregressive: use previous prediction or Ground Truth (Teacher Forcing)\n        \n        for t in range(self.seq_target):\n            combined = torch.cat((x, hx), 2)\n            gates = self.gate(combined)\n            resetgate, updategate = torch.split(gates, self.dim_in_dec, dim=2)\n            resetgate = torch.sigmoid(resetgate)\n            updategate = torch.sigmoid(updategate)\n            \n            combined_update = torch.cat((x, (resetgate * hx)), 2)\n            cy = torch.tanh(self.update(combined_update))\n            hy = updategate * hx + (1 - updategate) * cy\n            hx = hy\n            yt = torch.sigmoid(hy.matmul(self.W) + self.b)\n            output_inner.append(yt)\n            x = yt # Feed output as input for next step (simple autoregressive)\n            \n        res = torch.stack(output_inner, dim=1)\n        return res\n\nclass Enc_Dec_MRA(nn.Module):\n    def __init__(self, seq_target, dim_in, dim_out, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Enc_Dec_MRA, self).__init__()\n        self.dim_in = dim_in\n        self.linear_in = nn.Linear(dim_in, dim_in) # Projection to hidden\n        self.Encoder = Encoder_GRU_MRA(dim_in, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.Decoder = Decoder_GRU_MRA(seq_target, dim_in, dim_out, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.linear_out = nn.Linear(dim_out, 1) # Regress to 1 value (Risk)\n\n    def forward(self, inputs):\n        # inputs: [B, Seq, N, F]\n        inputs_proj = self.linear_in(inputs)\n        output_enc, encoder_hidden_state = self.Encoder(inputs_proj)\n        \n        # Decoder input: taking the last time step of encoder output\n        dec_input = output_enc[:, -1, :, :]\n        \n        output = self.Decoder(dec_input, encoder_hidden_state)\n        output = self.linear_out(output)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T05:08:30.323335Z","iopub.execute_input":"2025-12-20T05:08:30.323727Z","iopub.status.idle":"2025-12-20T05:08:30.358079Z","shell.execute_reply.started":"2025-12-20T05:08:30.323707Z","shell.execute_reply":"2025-12-20T05:08:30.357194Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- Reuse classes provided in prompt ---\n# (Including GraphConvolution, GCN, MGCN_Standard, BGCN, MRA_BGCN, Encoder_GRU_MRA, Decoder_GRU_MRA, Enc_Dec_MRA)\n\nclass GraphConvolution(Module):\n    def __init__(self, in_features, out_features, device, bias=True):\n        super(GraphConvolution, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.DEVICE = device\n        self.weight = Parameter(torch.FloatTensor(in_features, out_features).to(self.DEVICE))\n        if bias:\n            self.bias = Parameter(torch.FloatTensor(out_features).to(self.DEVICE))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        if self.bias is not None:\n            self.bias.data.uniform_(-stdv, stdv)\n\n    def forward(self, input, adj):\n        support = torch.mm(input, self.weight)\n        output = torch.spmm(adj, support)\n        if self.bias is not None:\n            return output + self.bias\n        else:\n            return output\n\nclass GCN(nn.Module):\n    def __init__(self, L_tilde, dim_in, dim_out, order_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(GCN, self).__init__()\n        self.DEVICE = device\n        self.order_K = order_K\n        self.L_tilde = L_tilde\n        self.dim_in = dim_in\n        self.dim_out = dim_out\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(dim_in, dim_out)) for _ in range(order_K)])\n        self.weights = nn.Parameter(torch.FloatTensor(size=(dim_out, dim_out)))\n        self.biases = nn.Parameter(torch.FloatTensor(size=(dim_out,)))\n        self._in_drop = in_drop\n        self._gcn_drop = gcn_drop\n        self._residual = residual\n        self.linear = nn.Linear(dim_in, dim_out)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        for theta in self.Theta:\n            nn.init.xavier_uniform_(theta)\n        nn.init.xavier_uniform_(self.weights)\n        nn.init.zeros_(self.biases)\n\n    def forward(self, x, state=None, M=None):\n        batch_size, num_of_vertices, in_channels = x.shape\n        output = torch.zeros(batch_size, num_of_vertices, self.dim_out).to(self.DEVICE)\n        cheb_polynomials = cheb_polynomial(self.L_tilde, self.order_K)\n        \n        if state is not None:\n             # Logic xử lý tương tác bipartite (M)\n            s = torch.einsum('ij,jkm->ikm', M, state.permute(1, 0, 2)).permute(1, 0, 2)\n            x = torch.cat((x, s), dim=-1)\n            \n        x0 = x\n        if self._in_drop != 0:\n            x = torch.dropout(x, 1.0 - self._in_drop, train=True)\n            \n        # Do input x thay đổi dimension nếu có state gộp vào\n        # Cần điều chỉnh linear layer nếu dimensions thay đổi dynamic (đơn giản hóa ở đây giả định dim khớp)\n        \n        for k in range(self.order_K):\n            # Chebyshev recurrence\n            # [Batch, N, Fin] * [N, N] -> [Batch, N, Fin] * [Fin, Fout]\n            # PyTorch matmul handles broadcasting\n            theta = self.Theta[k]\n            # Fix dimension mismatch hack for demo if state injection changes dim\n            if x.shape[-1] != theta.shape[0]: \n                # Re-init generic linear projection for simplicity in this wrapper\n                x_proj = nn.Linear(x.shape[-1], theta.shape[0]).to(self.DEVICE)(x)\n                support = x_proj.permute(0, 2, 1).matmul(cheb_polynomials[k]).permute(0, 2, 1).matmul(theta)\n            else:\n                support = x.permute(0, 2, 1).matmul(cheb_polynomials[k]).permute(0, 2, 1).matmul(theta)\n            output = output + support\n            \n        output = torch.matmul(output, self.weights)\n        output = output + self.biases\n        res = F.relu(output)\n        if self._gcn_drop != 0.0:\n            res = torch.dropout(res, 1.0 - self._gcn_drop, train=True)\n        if self._residual:\n            if x0.shape[-1] != self.dim_out:\n                x0 = nn.Linear(x0.shape[-1], self.dim_out).to(self.DEVICE)(x0)\n            res = res + x0\n        return res\n\nclass BGCN(nn.Module):\n    def __init__(self, adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(BGCN, self).__init__()\n        self.DEVICE = device\n        self.K = range_K\n        self._M = M\n        GCN_khops_node = []\n        for k in range(self.K):\n            if k == 0:\n                GCN_khops_node.append(GCN(adj_node, dim_in_node, dim_out_node, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual))\n            else:\n                # Dim in increased due to edge interaction\n                GCN_khops_node.append(GCN(adj_node, dim_out_node + dim_out_edge, dim_out_node, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual))\n        self.GCN_khops_node = nn.ModuleList(GCN_khops_node)\n        self.GCN_khops_edge = nn.ModuleList([GCN(adj_edge, dim_out_edge, dim_out_edge, k + 1, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual) for k in range(self.K)])\n        self.W_b = nn.Parameter(torch.FloatTensor(dim_in_node, dim_out_edge))\n        nn.init.xavier_uniform_(self.W_b)\n\n    def forward(self, X):\n        Xs = []\n        # Initial Edge Features derived from Nodes via Incidence Matrix M\n        # X: [Batch, N, F] -> [Batch, N, F] * [N, E] (via M) -> needs careful mapping\n        # Z0 calculation: M^T * X * W_b\n        # M: [N, E] -> M.T: [E, N]\n        # X: [B, N, F]\n        # X permute: [B, F, N]\n        \n        # Simplified logic for M interaction\n        X_flat = X.permute(0, 2, 1) # [B, F, N]\n        Z0 = torch.matmul(X_flat, self._M) # [B, F, E]\n        Z0 = Z0.permute(0, 2, 1) # [B, E, F]\n        Z0 = torch.matmul(Z0, self.W_b) if Z0.shape[-1] == self.W_b.shape[0] else nn.Linear(Z0.shape[-1], self.W_b.shape[1]).to(self.DEVICE)(Z0)\n\n        for k in range(self.K):\n            Z0 = self.GCN_khops_edge[k](Z0)\n            if k == 0:\n                X = self.GCN_khops_node[k](X)\n            else:\n                X = self.GCN_khops_node[k](X, Z0, self._M)\n            Xs.append(X)\n        Xs = torch.stack(Xs)\n        return Xs\n\nclass MRA_BGCN(nn.Module):\n    def __init__(self, adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, dim_out, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(MRA_BGCN, self).__init__()\n        self.DEVICE = device\n        self.dim_out = dim_out\n        self.W_a = nn.Parameter(torch.FloatTensor(dim_out_node, dim_out_node)) # Fixed dim mapping\n        self.U = nn.Parameter(torch.FloatTensor(dim_out_node))\n        self.BGCN = BGCN(adj_node, adj_edge, dim_in_node, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        nn.init.xavier_uniform_(self.W_a)\n        nn.init.uniform_(self.U)\n\n    def forward(self, X):\n        input = self.BGCN(X) # [K, B, N, F_out]\n        # Attention mechanism\n        # input: [K, B, N, F]\n        e = torch.einsum('kbnf,ff->kbn', input, self.W_a) # Simplified attention\n        e = torch.einsum('kbn,f->kbn', e, self.U) # This logic was slightly broken in prompt, simplified here\n        \n        # Corrected Attention logic based on shapes\n        # input: [K, Batch, Node, Feat]\n        temp = torch.matmul(input, self.W_a) \n        e = torch.matmul(temp, self.U) # [K, Batch, Node]\n        \n        alpha = F.softmax(e, dim=0).unsqueeze(-1) # Softmax over K\n        h = torch.sum(input * alpha, dim=0)\n        \n        # Project to dim_out if needed\n        if h.shape[-1] != self.dim_out:\n            h = nn.Linear(h.shape[-1], self.dim_out).to(self.DEVICE)(h)\n            \n        return h\n\nclass Encoder_GRU_MRA(nn.Module):\n    def __init__(self, dim_in_enc, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Encoder_GRU_MRA, self).__init__()\n        self.DEVICE = device\n        self.dim_in_enc = dim_in_enc\n        # Input to gate is cat(x, h), so dim is feature + hidden\n        self.gate = MRA_BGCN(adj_node, adj_edge, self.dim_in_enc * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_enc * 2, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.update = MRA_BGCN(adj_node, adj_edge, self.dim_in_enc * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_enc, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.W = nn.Parameter(torch.FloatTensor(self.dim_in_enc, self.dim_in_enc))\n        self.b = nn.Parameter(torch.FloatTensor(self.dim_in_enc, ))\n        nn.init.xavier_uniform_(self.W)\n        nn.init.zeros_(self.b)\n\n    def forward(self, inputs=None, hidden_state=None):\n        batch_size, seq_len, num_vertice, feature = inputs.shape\n        output_inner = []\n        if hidden_state is None:\n            hx = torch.zeros((batch_size, num_vertice, feature)).to(self.DEVICE)\n        else:\n            hx = hidden_state\n        for index in range(seq_len):\n            x = inputs[:, index]\n            combined = torch.cat((x, hx), 2)\n            gates = self.gate(combined)\n            resetgate, updategate = torch.split(gates, self.dim_in_enc, dim=2)\n            resetgate = torch.sigmoid(resetgate)\n            updategate = torch.sigmoid(updategate)\n            \n            combined_update = torch.cat((x, (resetgate * hx)), 2)\n            cy = torch.tanh(self.update(combined_update))\n            hy = updategate * hx + (1.0 - updategate) * cy\n            hx = hy\n            yt = torch.sigmoid(hy.matmul(self.W) + self.b)\n            output_inner.append(yt)\n        output_inner = torch.stack(output_inner, dim=1) # [B, Seq, N, F]\n        return output_inner, hx\n\nclass Decoder_GRU_MRA(nn.Module):\n    def __init__(self, seq_target, dim_in_dec, dim_out_dec, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Decoder_GRU_MRA, self).__init__()\n        self.DEVICE = device\n        self.seq_target = seq_target\n        self.dim_in_dec = dim_in_dec\n        self.dim_out_dec = dim_out_dec\n        self.gate = MRA_BGCN(adj_node, adj_edge, self.dim_in_dec * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_dec * 2, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.update = MRA_BGCN(adj_node, adj_edge, self.dim_in_dec * 2, dim_out_node, dim_out_edge, M, range_K, self.dim_in_dec, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.W = nn.Parameter(torch.FloatTensor(self.dim_in_dec, self.dim_out_dec))\n        self.b = nn.Parameter(torch.FloatTensor(self.dim_out_dec, ))\n        nn.init.xavier_uniform_(self.W)\n        nn.init.zeros_(self.b)\n\n    def forward(self, inputs=None, hidden_state=None):\n        # Inputs here is usually the last state of encoder or previous pred\n        batch_size, num_vertice, feature = inputs.shape\n        output_inner = []\n        hx = hidden_state\n        x = inputs # Autoregressive: use previous prediction or Ground Truth (Teacher Forcing)\n        \n        for t in range(self.seq_target):\n            combined = torch.cat((x, hx), 2)\n            gates = self.gate(combined)\n            resetgate, updategate = torch.split(gates, self.dim_in_dec, dim=2)\n            resetgate = torch.sigmoid(resetgate)\n            updategate = torch.sigmoid(updategate)\n            \n            combined_update = torch.cat((x, (resetgate * hx)), 2)\n            cy = torch.tanh(self.update(combined_update))\n            hy = updategate * hx + (1 - updategate) * cy\n            hx = hy\n            yt = torch.sigmoid(hy.matmul(self.W) + self.b)\n            output_inner.append(yt)\n            x = yt # Feed output as input for next step (simple autoregressive)\n            \n        res = torch.stack(output_inner, dim=1)\n        return res\n\nclass Enc_Dec_MRA(nn.Module):\n    def __init__(self, seq_target, dim_in, dim_out, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=0.0, gcn_drop=0.0, residual=False):\n        super(Enc_Dec_MRA, self).__init__()\n        self.dim_in = dim_in\n        self.linear_in = nn.Linear(dim_in, dim_in) # Projection to hidden\n        self.Encoder = Encoder_GRU_MRA(dim_in, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.Decoder = Decoder_GRU_MRA(seq_target, dim_in, dim_out, adj_node, adj_edge, dim_out_node, dim_out_edge, M, range_K, device, in_drop=in_drop, gcn_drop=gcn_drop, residual=residual)\n        self.linear_out = nn.Linear(dim_out, 1) # Regress to 1 value (Risk)\n\n    def forward(self, inputs):\n        # inputs: [B, Seq, N, F]\n        inputs_proj = self.linear_in(inputs)\n        output_enc, encoder_hidden_state = self.Encoder(inputs_proj)\n        \n        # Decoder input: taking the last time step of encoder output\n        dec_input = output_enc[:, -1, :, :]\n        \n        output = self.Decoder(dec_input, encoder_hidden_state)\n        output = self.linear_out(output)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T05:08:30.358861Z","iopub.execute_input":"2025-12-20T05:08:30.359061Z","iopub.status.idle":"2025-12-20T05:08:30.401659Z","shell.execute_reply.started":"2025-12-20T05:08:30.359045Z","shell.execute_reply":"2025-12-20T05:08:30.400851Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def main():\n    # --- Configurations ---\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {DEVICE}\")\n    \n    city = 'Seoul'\n    year = '2016'\n    length = 12 # Input sequence length\n    n_steps = 6 # Output sequence length (Prediction horizon)\n    epochs = 50\n    batch_size = 32\n    lr = 0.001\n    \n    # --- Data Loading ---\n    # NOTE: You must have the data files in ./datasets/ or usage the mock loader\n    # Using the simulation loader defined in Part 1 to make this script runnable immediately\n    X_train, Y_train, X_test, Y_test, adj_mx = load_mgtar_data('/kaggle/input/mg-tar', city, year, length, n_steps)\n    \n    print(f\"Train Shape: {X_train.shape}, {Y_train.shape}\")\n    print(f\"Adj Shape: {adj_mx.shape}\")\n    \n    # --- Graph Preprocessing for MRA-GCN ---\n    # 1. Laplacian for Nodes\n    L_tilde_node = torch.from_numpy(scaled_Laplacian(adj_mx)).to(DEVICE)\n    \n    # 2. Incidence Matrix M and Edge Graph (Required by BGCN)\n    M_np, adj_edge_np = get_incidence_matrix(adj_mx)\n    M = torch.from_numpy(M_np).to(DEVICE)\n    \n    # 3. Laplacian for Edges\n    if adj_edge_np.sum() == 0:\n        # Fallback if graph is disconnected or no edges\n        L_tilde_edge = torch.eye(M.shape[1]).to(DEVICE)\n    else:\n        L_tilde_edge = torch.from_numpy(scaled_Laplacian(adj_edge_np)).to(DEVICE)\n        \n    print(f\"Incidence Matrix M shape: {M.shape}\")\n    print(f\"Edge Graph shape: {L_tilde_edge.shape}\")\n\n    # --- Dataset & Loader ---\n    train_dataset = MGTARDataset(X_train, Y_train)\n    test_dataset = MGTARDataset(X_test, Y_test)\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    \n    # --- Model Initialization ---\n    dim_in = X_train.shape[-1]\n    dim_out = 32 # Hidden dimension\n    dim_out_node = 32\n    dim_out_edge = 32\n    range_K = 2 # Chebyshev order\n    \n    model = Enc_Dec_MRA(\n        seq_target=n_steps,\n        dim_in=dim_in,\n        dim_out=dim_out,\n        adj_node=L_tilde_node,\n        adj_edge=L_tilde_edge,\n        dim_out_node=dim_out_node,\n        dim_out_edge=dim_out_edge,\n        M=M,\n        range_K=range_K,\n        device=DEVICE\n    ).to(DEVICE)\n    \n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    criterion = nn.MSELoss()\n    \n    # --- Training Loop ---\n    print(\"\\nStarting Training...\")\n    history = {'train_loss': [], 'val_mae': [], 'val_rmse': [], 'val_pcc': []}\n    \n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for i, (x_batch, y_batch) in enumerate(train_loader):\n            x_batch = x_batch.to(DEVICE)\n            y_batch = y_batch.to(DEVICE)\n            \n            optimizer.zero_grad()\n            output = model(x_batch)\n            \n            # MG_TAR labels are often [B, T, N, 1], model output [B, T, N, 1]\n            loss = criterion(output, y_batch)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n        avg_loss = total_loss / len(train_loader)\n        history['train_loss'].append(avg_loss)\n        \n        # --- Evaluation ---\n        if (epoch + 1) % 5 == 0:\n            model.eval()\n            all_preds = []\n            all_targets = []\n            with torch.no_grad():\n                for x_batch, y_batch in test_loader:\n                    x_batch = x_batch.to(DEVICE)\n                    output = model(x_batch)\n                    all_preds.append(output.cpu())\n                    all_targets.append(y_batch.cpu())\n            \n            all_preds = torch.cat(all_preds, dim=0)\n            all_targets = torch.cat(all_targets, dim=0)\n            \n            mae, rmse, pcc = compute_metrics(all_preds, all_targets)\n            \n            history['val_mae'].append(mae)\n            history['val_rmse'].append(rmse)\n            history['val_pcc'].append(pcc)\n            \n            print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Val MAE: {mae:.4f} | Val RMSE: {rmse:.4f} | Val PCC: {pcc:.4f}\")\n\n    print(\"\\nTraining Finished.\")\n    print(f\"Final Evaluation -> MAE: {history['val_mae'][-1]:.4f}, RMSE: {history['val_rmse'][-1]:.4f}, PCC: {history['val_pcc'][-1]:.4f}\")\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T05:08:30.402505Z","iopub.execute_input":"2025-12-20T05:08:30.402971Z","iopub.status.idle":"2025-12-20T05:11:48.397101Z","shell.execute_reply.started":"2025-12-20T05:08:30.402947Z","shell.execute_reply":"2025-12-20T05:11:48.396385Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading Data (Simulating MG_TAR structure)...\nTrain Shape: (500, 12, 25, 15), (500, 6, 25, 1)\nAdj Shape: (25, 25)\nIncidence Matrix M shape: torch.Size([25, 311])\nEdge Graph shape: torch.Size([311, 311])\n\nStarting Training...\nEpoch 5/50 | Loss: 0.0837 | Val MAE: 0.2494 | Val RMSE: 0.2881 | Val PCC: 0.0108\nEpoch 10/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2878 | Val PCC: 0.0110\nEpoch 15/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2878 | Val PCC: -0.0020\nEpoch 20/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2878 | Val PCC: 0.0045\nEpoch 25/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2877 | Val PCC: -0.0004\nEpoch 30/50 | Loss: 0.0834 | Val MAE: 0.2492 | Val RMSE: 0.2877 | Val PCC: -0.0026\nEpoch 35/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2878 | Val PCC: -0.0010\nEpoch 40/50 | Loss: 0.0835 | Val MAE: 0.2493 | Val RMSE: 0.2878 | Val PCC: -0.0004\nEpoch 45/50 | Loss: 0.0836 | Val MAE: 0.2492 | Val RMSE: 0.2877 | Val PCC: 0.0016\nEpoch 50/50 | Loss: 0.0835 | Val MAE: 0.2492 | Val RMSE: 0.2877 | Val PCC: 0.0069\n\nTraining Finished.\nFinal Evaluation -> MAE: 0.2492, RMSE: 0.2877, PCC: 0.0069\n","output_type":"stream"}],"execution_count":4}]}