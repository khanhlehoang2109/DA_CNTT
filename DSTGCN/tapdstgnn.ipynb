{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13060620,"sourceType":"datasetVersion","datasetId":8270673}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install osmnx torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T16:24:20.284314Z","iopub.execute_input":"2025-12-17T16:24:20.284627Z","iopub.status.idle":"2025-12-17T16:24:26.907347Z","shell.execute_reply.started":"2025-12-17T16:24:20.284590Z","shell.execute_reply":"2025-12-17T16:24:26.906469Z"}},"outputs":[{"name":"stdout","text":"Collecting osmnx\n  Downloading osmnx-2.0.7-py3-none-any.whl.metadata (4.9 kB)\nCollecting torch_geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: geopandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from osmnx) (1.1.1)\nRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from osmnx) (3.5)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.0.2)\nRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.2.2)\nRequirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.32.5)\nRequirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.1.2)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\nRequirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (0.11.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (25.0)\nRequirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (3.7.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2025.11.12)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\nDownloading osmnx-2.0.7-py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric, osmnx\nSuccessfully installed osmnx-2.0.7 torch_geometric-2.7.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys\nimport math\nimport time\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nfrom torch.utils.data import Dataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.nn.inits import reset, uniform, zeros\nfrom torch_geometric.utils import from_networkx\nfrom sklearn.metrics import f1_score, average_precision_score, roc_auc_score, mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import pearsonr\nfrom tqdm import tqdm\nfrom typing import Union, Tuple, Callable, Optional\n\n# Thiết lập device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# ==========================================\n# 1. UTILS: COORD TRANSFORM\n# ==========================================\nx_pi = 3.14159265358979324 * 3000.0 / 180.0\npi = 3.1415926535897932384626\na = 6378245.0\nee = 0.00669342162296594323\n\ndef gcj02_to_bd09(lng, lat):\n    z = math.sqrt(lng * lng + lat * lat) + 0.00002 * math.sin(lat * x_pi)\n    theta = math.atan2(lat, lng) + 0.000003 * math.cos(lng * x_pi)\n    bd_lng = z * math.cos(theta) + 0.0065\n    bd_lat = z * math.sin(theta) + 0.006\n    return [bd_lng, bd_lat]\n\ndef bd09_to_gcj02(bd_lon, bd_lat):\n    x = bd_lon - 0.0065\n    y = bd_lat - 0.006\n    z = math.sqrt(x * x + y * y) - 0.00002 * math.sin(y * x_pi)\n    theta = math.atan2(y, x) - 0.000003 * math.cos(x * x_pi)\n    gg_lng = z * math.cos(theta)\n    gg_lat = z * math.sin(theta)\n    return [gg_lng, gg_lat]\n\ndef wgs84_to_gcj02(lng, lat):\n    if out_of_china(lng, lat):\n        return [lng, lat]\n    dlat = _transformlat(lng - 105.0, lat - 35.0)\n    dlng = _transformlng(lng - 105.0, lat - 35.0)\n    radlat = lat / 180.0 * pi\n    magic = math.sin(radlat)\n    magic = 1 - ee * magic * magic\n    sqrtmagic = math.sqrt(magic)\n    dlat = (dlat * 180.0) / ((a * (1 - ee)) / (magic * sqrtmagic) * pi)\n    dlng = (dlng * 180.0) / (a / sqrtmagic * math.cos(radlat) * pi)\n    mglat = lat + dlat\n    mglng = lng + dlng\n    return [mglng, mglat]\n\ndef _transformlat(lng, lat):\n    ret = -100.0 + 2.0 * lng + 3.0 * lat + 0.2 * lat * lat + \\\n          0.1 * lng * lat + 0.2 * math.sqrt(math.fabs(lng))\n    ret += (20.0 * math.sin(6.0 * lng * pi) + 20.0 *\n            math.sin(2.0 * lng * pi)) * 2.0 / 3.0\n    ret += (20.0 * math.sin(lat * pi) + 40.0 *\n            math.sin(lat / 3.0 * pi)) * 2.0 / 3.0\n    ret += (160.0 * math.sin(lat / 12.0 * pi) + 320 *\n            math.sin(lat * pi / 30.0)) * 2.0 / 3.0\n    return ret\n\ndef _transformlng(lng, lat):\n    ret = 300.0 + lng + 2.0 * lat + 0.1 * lng * lng + \\\n          0.1 * lng * lat + 0.1 * math.sqrt(math.fabs(lng))\n    ret += (20.0 * math.sin(6.0 * lng * pi) + 20.0 *\n            math.sin(2.0 * lng * pi)) * 2.0 / 3.0\n    ret += (20.0 * math.sin(lng * pi) + 40.0 *\n            math.sin(lng / 3.0 * pi)) * 2.0 / 3.0\n    ret += (150.0 * math.sin(lng / 12.0 * pi) + 300.0 *\n            math.sin(lng / 30.0 * pi)) * 2.0 / 3.0\n    return ret\n\ndef out_of_china(lng, lat):\n    return not (lng > 73.66 and lng < 135.05 and lat > 3.86 and lat < 53.55)\n\ndef convert_by_type(lng, lat, type):\n    if type == 'g2b': return gcj02_to_bd09(lng, lat)\n    elif type == 'b2g': return bd09_to_gcj02(lng, lat)\n    elif type == 'w2g': return wgs84_to_gcj02(lng, lat)\n    elif type == 'g2w': return [lng, lat] # Placeholder for reverse if needed, or implement full\n    else: return [lng, lat]\n\n# ==========================================\n# 2. DATA CONTAINER & PREPROCESSING\n# ==========================================\n\nlongitudeMin = 116.09608\nlongitudeMax = 116.71040\nlatitudeMin = 39.69086\nlatitudeMax = 40.17647\n\n# Convert bounds\nlongitudeMin, latitudeMin = convert_by_type(lng=longitudeMin, lat=latitudeMin, type=\"g2w\")\nlongitudeMax, latitudeMax = convert_by_type(lng=longitudeMax, lat=latitudeMax, type=\"g2w\")\n\ndivideBound = 5\nwidthSingle = 0.01 / math.cos(latitudeMin / 180 * math.pi) / divideBound\nwidth = math.floor((longitudeMax - longitudeMin) / widthSingle)\nheightSingle = 0.01 / divideBound\nheight = math.floor((latitudeMax - latitudeMin) / heightSingle)\n\ndef fill_speed(speed_data):\n    date_range = pd.date_range(start=\"2018-08-01\", end=\"2018-11-01\", freq=\"1H\")[:-1]\n    speed_data = speed_data.resample(rule=\"1H\").mean()\n    \n    missing_dates = []\n    for date in date_range:\n        if date in speed_data.index:\n             if any(speed_data.loc[date].isna()):\n                missing_dates.append(date)\n        else:\n             missing_dates.append(date) # Handle totally missing index\n\n    print(f\"Found {len(missing_dates)} dates with missing data\")\n    one_week = datetime.timedelta(days=7)\n    \n    for date in tqdm(missing_dates, 'Fill speed'):\n        # Simple fill logic for demo stability\n        if date - one_week in speed_data.index:\n             speed_data.loc[date] = speed_data.loc[date - one_week]\n        else:\n             speed_data.loc[date] = speed_data.mean() # Fallback\n    return speed_data.fillna(0)\n\nimport datetime\n\nclass AccidentDataset(Dataset):\n    def __init__(self, k_order, network, node_attr, accident, weather, speed, \n                 sf_scaler=None, tf_scaler=None, ef_scaler=None):\n        self.k_order = k_order\n        self.network = network\n        self.nodes = node_attr\n        self.accident = accident\n        self.weather = weather\n        self.speed = speed\n        self.sf_scaler = sf_scaler\n        self.tf_scaler = tf_scaler\n        self.ef_scaler = ef_scaler\n\n    def __getitem__(self, sample_id):\n        _, _, accident_time, node_id, target = self.accident.iloc[sample_id]\n        \n        # 1. Subgraph extraction\n        neighbors = nx.single_source_shortest_path_length(self.network, node_id, cutoff=self.k_order)\n        neighbors.pop(node_id, None)\n        neighbors = [node_id] + sorted(neighbors.keys())\n        \n        sub_graph_nx = nx.subgraph(self.network, neighbors)\n        relabel_map = {old_label: new_label for new_label, old_label in enumerate(neighbors)}\n        sub_graph_nx = nx.relabel_nodes(sub_graph_nx, relabel_map)\n        \n        # --- FIX: XỬ LÝ TRƯỜNG HỢP KHÔNG CÓ CẠNH ---\n        edges = list(sub_graph_nx.edges)\n        if len(edges) > 0:\n            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n        else:\n            # Nếu không có cạnh, tạo tensor rỗng shape [2, 0]\n            edge_index = torch.empty((2, 0), dtype=torch.long)\n        # -------------------------------------------\n\n        # 2. Features Extraction\n        # Sửa warning 'H' -> 'h'\n        date_range = pd.date_range(end=accident_time.strftime(\"%Y%m%d %H\"), freq=\"1h\", periods=24)\n        \n        valid_dates = [d for d in date_range if d in self.speed.index]\n        if len(valid_dates) < 24:\n             selected_time = pd.DataFrame(0, index=date_range, columns=self.speed.columns)\n        else:\n             selected_time = self.speed.loc[date_range]\n\n        selected_nodes = self.nodes.loc[neighbors]\n        spatial_features = selected_nodes['spatial_features'].tolist()\n\n        x_ids = np.floor((selected_nodes['XCoord'].values - longitudeMin) / widthSingle).astype(np.int64)\n        y_ids = np.floor((selected_nodes['YCoord'].values - latitudeMin) / heightSingle).astype(np.int64)\n        \n        keys = [f'{y},{x}' for y, x in zip(y_ids, x_ids)]\n        valid_keys = [k for k in keys if k in selected_time.columns]\n        \n        if not valid_keys:\n             temporal_features = np.zeros((len(neighbors), 24))\n        else:\n            temp_vals = []\n            for k in keys:\n                if k in selected_time.columns:\n                    temp_vals.append(selected_time[k].values)\n                else:\n                    temp_vals.append(np.zeros(24))\n            temporal_features = np.array(temp_vals)\n\n        if date_range[-1] in self.weather.index:\n            weather_data = self.weather.loc[date_range[-1]].tolist()\n        else:\n            weather_data = [0] * len(self.weather.columns)\n\n        external_features = weather_data + [accident_time.month, accident_time.day, accident_time.dayofweek,\n                                            accident_time.hour, int(accident_time.dayofweek >= 5)]\n\n        # Scaling\n        if self.sf_scaler[0] is not None:\n            spatial_features = (np.array(spatial_features) - self.sf_scaler[0]) / (self.sf_scaler[1] + 1e-5)\n        if self.tf_scaler[0] is not None:\n             temporal_features = (np.array(temporal_features) - self.tf_scaler[0]) / (self.tf_scaler[1] + 1e-5)\n        if self.ef_scaler[0] is not None:\n             external_features = (np.array(external_features) - self.ef_scaler[0]) / (self.ef_scaler[1] + 1e-5)\n\n        x_spatial = torch.tensor(spatial_features).float()\n        x_temporal = torch.tensor(temporal_features).float()\n        x_external = torch.tensor(external_features).float().unsqueeze(0).repeat(len(neighbors), 1)\n        \n        x = torch.cat([x_spatial, x_temporal, x_external], dim=1)\n        y = torch.tensor(target).long()\n\n        target_mask = torch.zeros(len(neighbors), dtype=torch.bool)\n        target_mask[0] = True\n        data = Data(x=x, edge_index=edge_index, y=y, target_mask=target_mask)\n        \n        # --- FIX: TÍNH NUM_EDGES AN TOÀN ---\n        num_edges = edge_index.shape[1] \n        # -----------------------------------\n        \n        data.edge_attr_dir = torch.zeros((num_edges, 1))\n        data.edge_attr_ang = torch.zeros((num_edges, 1))\n        data.edge_attr = torch.zeros((num_edges, 1))\n        \n        return data\n\n    def __len__(self):\n        return len(self.accident)\n\n# Helper to get metadata (Mocking the missing h5 attributes)\ndef get_attribute_mock(nodes, speed, weather):\n    # This is a simplified mock. In real usage, calculate mean/std from Training set only.\n    sf_mean = 0 \n    sf_std = 1\n    tf_mean = 0\n    tf_std = 1\n    ef_mean = 0\n    ef_std = 1\n    return sf_mean, sf_std, tf_mean, tf_std, ef_mean, ef_std\n\ndef get_data_loaders(k_order, batch_size):\n    # Paths (Ensure these exist in your Kaggle environment)\n    network_path = r'/kaggle/input/dstgcn-dataset/beijing_roadnet.gpickle'\n    node_attr_path = r'/kaggle/input/dstgcn-dataset/edges_data.h5'\n    accident_path = r'/kaggle/input/dstgcn-dataset/accident.h5'\n    weather_path = \"/kaggle/input/dstgcn-dataset/weather.h5\"\n    speed_path = \"/kaggle/input/dstgcn-dataset/all_grids_speed.h5\"\n\n    print(\"Loading data...\")\n    with open(network_path, 'rb') as f:\n        network = pickle.load(f)\n    nodes = pd.read_hdf(node_attr_path)\n    weather = pd.read_hdf(weather_path)\n    # Mocking fill_speed for speed (requires data)\n    # speed = fill_speed(pd.read_hdf(speed_path)) \n    speed = pd.read_hdf(speed_path) # Assuming clean for now or implement fill_speed fully\n\n    # Mock scaler stats\n    sf_mean, sf_std, tf_mean, tf_std, ef_mean, ef_std = get_attribute_mock(nodes, speed, weather)\n\n    dls = dict()\n    for key in ['train', 'validate', 'test']:\n        try:\n            accident = pd.read_hdf(accident_path, key=key)\n        except KeyError:\n            print(f\"Key {key} not found in accident.h5, skipping or using train\")\n            continue\n            \n        dataset = AccidentDataset(k_order, network, nodes, accident, weather, speed,\n                                  sf_scaler=(sf_mean, sf_std),\n                                  tf_scaler=(tf_mean, tf_std),\n                                  ef_scaler=(ef_mean, ef_std))\n        \n        # Use PyG DataLoader\n        dls[key] = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=(key=='train'), num_workers=0)\n    \n    return dls\n\n# ==========================================\n# 3. MODEL: TRAVELConv & TRAVELNet\n# ==========================================\n\nclass TRAVELConv(MessagePassing):\n    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n                 out_channels: int, nn: Callable, aggr: str = 'add',\n                 root_weight: bool = True, bias: bool = True, **kwargs):\n        super(TRAVELConv, self).__init__(aggr=aggr, **kwargs)\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.nn = nn\n        self.aggr = aggr\n\n        if isinstance(in_channels, int):\n            in_channels = (in_channels, in_channels)\n\n        self.in_channels_l = in_channels[0]\n\n        if root_weight:\n            self.root = Parameter(torch.Tensor(in_channels[1], out_channels))\n        else:\n            self.register_parameter('root', None)\n\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter('bias', None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        reset(self.nn)\n        if self.root is not None:\n            uniform(self.root.size(0), self.root)\n        zeros(self.bias)\n\n\n    def forward(self, x: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], edge_index,\n                edge_attr=None, size=None) -> torch.Tensor:\n        if isinstance(x, torch.Tensor):\n            x = (x, x)\n\n        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size)\n\n        x_r = x[1]\n        if x_r is not None and self.root is not None:\n            out += torch.matmul(x_r, self.root)\n\n        if self.bias is not None:\n            out += self.bias\n        return out\n\n\n    def message(self, x_i, x_j, edge_attr):\n        # Concatenate Node features of neighbor (x_j) and Edge features\n        if edge_attr is not None:\n            inputs = torch.cat([x_j, edge_attr], dim=1)\n        else:\n            inputs = x_j\n        return self.nn(inputs)\n\nclass TRAVELNet(torch.nn.Module):\n    def __init__(self, node_feature_dim, edge_dir_dim, edge_ang_dim, num_classes, dim=64, p_dropout=0.5):\n        super(TRAVELNet, self).__init__()\n        self.p = p_dropout\n        convdim = 8\n        \n        # Node Encoder\n        self.node_encoder = nn.Sequential(nn.Linear(node_feature_dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim))\n        \n        # Edge Encoders\n        self.edge_encoder_dir = nn.Sequential(nn.Linear(edge_dir_dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim))\n        self.edge_encoder_ang = nn.Sequential(nn.Linear(edge_ang_dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim))\n        \n        # Conv Branch 1 (Direction)\n        nn1 = nn.Sequential(nn.Linear(dim + dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim), nn.LeakyReLU(), nn.Linear(dim, convdim))\n        self.conv1 = TRAVELConv(dim, convdim, nn1)\n        \n        nn2 = nn.Sequential(nn.Linear(2*convdim + dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim), nn.LeakyReLU(), nn.Linear(dim, num_classes))\n        self.conv2 = TRAVELConv(2*convdim, num_classes, nn2)\n        \n        self.bn1 = nn.BatchNorm1d(convdim*2)\n        \n        # Conv Branch 2 (Angle)\n        nn1_2 = nn.Sequential(nn.Linear(dim + dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim), nn.LeakyReLU(), nn.Linear(dim, convdim))\n        self.conv1_2 = TRAVELConv(dim, convdim, nn1_2)\n        \n        nn2_2 = nn.Sequential(nn.Linear(2*convdim + dim, dim), nn.LeakyReLU(), nn.Linear(dim, dim), nn.LeakyReLU(), nn.Linear(dim, num_classes))\n        self.conv2_2 = TRAVELConv(2*convdim, num_classes, nn2_2)\n        \n        self.bn2 = nn.BatchNorm1d(num_classes*2)\n        self.fc = nn.Linear(num_classes*2, num_classes)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        \n        # Encode inputs\n        x = self.node_encoder(x)\n        \n        # Assume component_dir and component_ang are attached to data in batching or preprocessing\n        # If not present, create placeholders (Not ideal for performance but prevents crash)\n        if hasattr(data, 'component_dir'):\n            edge_attr_dir = self.edge_encoder_dir(data.component_dir)\n        else:\n            # Fallback for debugging\n            edge_attr_dir = self.edge_encoder_dir(torch.zeros(edge_index.size(1), 2).to(x.device)) # Assumed dim 2\n            \n        if hasattr(data, 'component_ang'):\n            edge_attr_ang = self.edge_encoder_ang(data.component_ang)\n        else:\n             edge_attr_ang = self.edge_encoder_ang(torch.zeros(edge_index.size(1), 2).to(x.device))\n\n        # Block 1\n        x1 = F.relu(self.conv1(x, edge_index, edge_attr_dir))\n        x2 = F.relu(self.conv1_2(x, edge_index, edge_attr_ang))\n        \n        x_concat = torch.cat((x1, x2), axis=1)\n        x_concat = self.bn1(x_concat)\n        x_concat = F.dropout(x_concat, p=self.p, training=self.training)\n        \n        # Block 2\n        x1_out = F.relu(self.conv2(x_concat, edge_index, edge_attr_dir))\n        x2_out = F.relu(self.conv2_2(x_concat, edge_index, edge_attr_ang))\n        \n        x_final = torch.cat((x1_out, x2_out), axis=1)\n        x_final = self.fc(x_final)\n        \n        return F.log_softmax(x_final, dim=1)\n\n# ==========================================\n# 4. TRAIN AND TEST LOOP\n# ==========================================\n\ndef train(model, data_loader, optimizer):\n    model.train()\n    total_loss = 0\n    for batch in data_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        \n        # Mock edge features (giữ nguyên logic cũ)\n        batch.component_dir = torch.cat([batch.edge_attr, batch.edge_attr_dir], dim=1).float()\n        batch.component_ang = torch.cat([batch.edge_attr, batch.edge_attr_ang], dim=1).float()\n        \n        out = model(batch)\n        \n        # --- FIX QUAN TRỌNG TẠI ĐÂY ---\n        # Chỉ lấy output của các node trung tâm (target nodes)\n        # out shape ban đầu: [Total_Nodes_in_Batch, 2] (ví dụ: 162, 2)\n        # batch.y shape: [Batch_Size] (ví dụ: 32)\n        \n        pred_nodes = out[batch.target_mask] # Shape sẽ thành [32, 2]\n        \n        loss = F.nll_loss(pred_nodes, batch.y)\n        # ------------------------------\n        \n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(data_loader)\n    \n@torch.no_grad()\ndef test(model, data_loader):\n    model.eval()\n    y_true = []\n    y_pred = []\n    y_scores = []\n    \n    for batch in data_loader:\n        batch = batch.to(device)\n        batch.component_dir = torch.cat([batch.edge_attr, batch.edge_attr_dir], dim=1).float()\n        batch.component_ang = torch.cat([batch.edge_attr, batch.edge_attr_ang], dim=1).float()\n        \n        out = model(batch)\n        \n        # --- FIX ÁP DỤNG MASK CHO TEST ---\n        pred_nodes = out[batch.target_mask] # Lọc ra các node target\n        \n        pred = pred_nodes.max(1)[1]\n        y_scores_batch = torch.exp(pred_nodes)[:, 1] # Lấy xác suất lớp 1\n        # ---------------------------------\n        \n        y_true.append(batch.y.cpu().numpy())\n        y_pred.append(pred.cpu().numpy())\n        y_scores.append(y_scores_batch.cpu().numpy()) \n\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    y_scores = np.concatenate(y_scores)\n    \n    # (Phần tính toán metrics bên dưới giữ nguyên)\n    f1 = f1_score(y_true, y_pred, average='binary')\n    acc = (y_true == y_pred).sum() / len(y_true)\n    try:\n        auc = roc_auc_score(y_true, y_scores)\n        ap = average_precision_score(y_true, y_scores)\n    except ValueError:\n        auc = 0\n        ap = 0\n\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    pcc, _ = pearsonr(y_true, y_pred)\n\n    return f1, acc, ap, auc, mae, rmse, pcc\n\ndef train_loop(model, loaders, optimizer, num_epochs, model_name='TRAVEL'):\n    print(f\"Start training {model_name}...\")\n    best_f1 = 0\n    \n    for epoch in range(1, num_epochs + 1):\n        train_loss = train(model, loaders['train'], optimizer)\n        \n        # Evaluate on Val (or Test directly if Val not present)\n        eval_key = 'validate' if 'validate' in loaders else 'test'\n        val_res = test(model, loaders[eval_key])\n        f1, acc, map_score, auc, mae, rmse, pcc = val_res\n        \n        log = 'Epoch: {:03d}, Loss: {:.4f}, F1: {:.4f}, Acc: {:.4f}, AUC: {:.4f}, MAE: {:.4f}, RMSE: {:.4f}, PCC: {:.4f}'\n        print(log.format(epoch, train_loss, f1, acc, auc, mae, rmse, pcc))\n\n# ==========================================\n# 5. MAIN EXECUTION\n# ==========================================\n\nif __name__ == \"__main__\":\n    # Settings\n    BATCH_SIZE = 32\n    K_ORDER = 1 # Neighbor depth\n    NUM_EPOCHS = 20\n    HIDDEN_DIM = 64\n    NUM_CLASSES = 2 # 0 or 1\n    \n    # 1. Load Data\n    try:\n        loaders = get_data_loaders(K_ORDER, BATCH_SIZE)\n    except FileNotFoundError as e:\n        print(f\"Error: {e}\")\n        print(\"Please ensure dataset files are in /kaggle/input/dstgcn-dataset/\")\n        sys.exit(1)\n    \n    if 'train' not in loaders:\n        print(\"No training data found. Exiting.\")\n        sys.exit(1)\n\n    # 2. Inspect a batch to determine input dimensions dynamically\n    sample_batch = next(iter(loaders['train']))\n    node_feat_dim = sample_batch.x.size(1)\n    # Edge attr calculated as concatenation of [edge_attr, edge_attr_dir/ang]\n    # In Dataset we made placeholders of size 1. So 1+1 = 2 dimensions.\n    edge_dim = 2 \n    \n    # 3. Initialize Model\n    model = TRAVELNet(\n        node_feature_dim=node_feat_dim,\n        edge_dir_dim=edge_dim,\n        edge_ang_dim=edge_dim,\n        num_classes=NUM_CLASSES,\n        dim=HIDDEN_DIM\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n\n    # 4. Run Training\n    train_loop(model, loaders, optimizer, NUM_EPOCHS)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-17T16:32:29.128960Z","iopub.execute_input":"2025-12-17T16:32:29.129308Z","iopub.status.idle":"2025-12-17T17:03:24.068622Z","shell.execute_reply.started":"2025-12-17T16:32:29.129275Z","shell.execute_reply":"2025-12-17T17:03:24.067947Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nStart training TRAVEL...\nEpoch: 001, Loss: 0.4593, F1: 0.8417, Acc: 0.8422, AUC: 0.9246, MAE: 0.1578, RMSE: 0.3973, PCC: 0.6844\nEpoch: 002, Loss: 0.3828, F1: 0.8511, Acc: 0.8578, AUC: 0.9360, MAE: 0.1422, RMSE: 0.3771, PCC: 0.7186\nEpoch: 003, Loss: 0.3634, F1: 0.8127, Acc: 0.8344, AUC: 0.9380, MAE: 0.1656, RMSE: 0.4070, PCC: 0.6874\nEpoch: 004, Loss: 0.3586, F1: 0.8768, Acc: 0.8758, AUC: 0.9383, MAE: 0.1242, RMSE: 0.3524, PCC: 0.7517\nEpoch: 005, Loss: 0.3447, F1: 0.8692, Acc: 0.8742, AUC: 0.9469, MAE: 0.1258, RMSE: 0.3547, PCC: 0.7506\nEpoch: 006, Loss: 0.3459, F1: 0.8716, Acc: 0.8695, AUC: 0.9441, MAE: 0.1305, RMSE: 0.3612, PCC: 0.7395\nEpoch: 007, Loss: 0.3364, F1: 0.8743, Acc: 0.8641, AUC: 0.9461, MAE: 0.1359, RMSE: 0.3687, PCC: 0.7379\nEpoch: 008, Loss: 0.3442, F1: 0.8662, Acc: 0.8680, AUC: 0.9405, MAE: 0.1320, RMSE: 0.3634, PCC: 0.7362\nEpoch: 009, Loss: 0.3445, F1: 0.8711, Acc: 0.8641, AUC: 0.9471, MAE: 0.1359, RMSE: 0.3687, PCC: 0.7325\nEpoch: 010, Loss: 0.3318, F1: 0.8828, Acc: 0.8789, AUC: 0.9473, MAE: 0.1211, RMSE: 0.3480, PCC: 0.7595\nEpoch: 011, Loss: 0.3212, F1: 0.8767, Acc: 0.8680, AUC: 0.9489, MAE: 0.1320, RMSE: 0.3634, PCC: 0.7435\nEpoch: 012, Loss: 0.3276, F1: 0.8345, Acc: 0.8500, AUC: 0.9453, MAE: 0.1500, RMSE: 0.3873, PCC: 0.7126\nEpoch: 013, Loss: 0.3215, F1: 0.8746, Acc: 0.8750, AUC: 0.9503, MAE: 0.1250, RMSE: 0.3536, PCC: 0.7500\nEpoch: 014, Loss: 0.3188, F1: 0.8723, Acc: 0.8773, AUC: 0.9530, MAE: 0.1227, RMSE: 0.3502, PCC: 0.7571\nEpoch: 015, Loss: 0.3124, F1: 0.8755, Acc: 0.8664, AUC: 0.9511, MAE: 0.1336, RMSE: 0.3655, PCC: 0.7407\nEpoch: 016, Loss: 0.3134, F1: 0.8727, Acc: 0.8648, AUC: 0.9484, MAE: 0.1352, RMSE: 0.3676, PCC: 0.7353\nEpoch: 017, Loss: 0.3085, F1: 0.8541, Acc: 0.8398, AUC: 0.9366, MAE: 0.1602, RMSE: 0.4002, PCC: 0.6930\nEpoch: 018, Loss: 0.3143, F1: 0.8602, Acc: 0.8461, AUC: 0.9494, MAE: 0.1539, RMSE: 0.3923, PCC: 0.7067\nEpoch: 019, Loss: 0.3160, F1: 0.8396, Acc: 0.8531, AUC: 0.9483, MAE: 0.1469, RMSE: 0.3832, PCC: 0.7165\nEpoch: 020, Loss: 0.3068, F1: 0.8789, Acc: 0.8797, AUC: 0.9522, MAE: 0.1203, RMSE: 0.3469, PCC: 0.7594\n","output_type":"stream"}],"execution_count":4}]}